{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from six.moves import urllib0\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SOURCE_URL = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "FILENAME = SOURCE_URL.split('/')[-1]\n",
    "DATA_DIR = './datasets'\n",
    "\n",
    "def maybe_download(data_dir):\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    if not os.path.isfile(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading {} {:.1f} %'.format(\n",
    "                FILENAME, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully donloaded', FILENAME, statinfo.st_size, 'bytes.')\n",
    "\n",
    "def load(data_dir, subset='train'):\n",
    "    maybe_download(data_dir)\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    \n",
    "    f = gzip.open(filepath, 'rb')\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    train_set, valid_set, test_set = u.load()\n",
    "    f.close()\n",
    "    \n",
    "    if subset == 'train':\n",
    "        trainx, trainy = train_set\n",
    "        trainx = trainx.astype(np.float32).reshape(trainx.shape[0], 28, 28)\n",
    "        trainy = trainy.astype(np.uint8)\n",
    "        return trainx, trainy\n",
    "    elif subset == 'test':\n",
    "        testx, testy = test_set\n",
    "        testx = testx.astype(np.float32).reshape(testx.shape[0], 28, 28)\n",
    "        testy = testy.astype(np.uint8)\n",
    "        return testx, testy\n",
    "    elif subset== 'valid':\n",
    "        validx, validy = valid_set\n",
    "        validx = validx.astype(np.float32).reshape(validx.shape[0], 28, 28)\n",
    "        validy = validy.astype(np.uint8)\n",
    "        return validx, validy\n",
    "    else:\n",
    "        raise NotImplementedError('subset should be train or valid or test')\n",
    "\n",
    "# Load data\n",
    "train_data, train_label = load(DATA_DIR, 'train')\n",
    "valid_data, valid_label = load(DATA_DIR, 'valid')\n",
    "test_data, test_label = load(DATA_DIR, 'test')\n",
    "\n",
    "# concatenate train and valid data as train data\n",
    "train_data = np.concatenate((train_data, valid_data))\n",
    "train_label = np.concatenate((train_label, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 확인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[0]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,by):\n",
    "    X = tf.expand_dims(X, axis = 3)\n",
    "    with tf.variable_scope('first'):\n",
    "        outs = tf.layers.conv2d(X, 128, 3, padding = 'same') #filter : 128, kernel : 3\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2) #stride : 2, size : 2\n",
    "    with tf.variable_scope('second'):\n",
    "        outs = tf.layers.conv2d(outs,256,3, padding = 'same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2)\n",
    "    with tf.variable_scope('third'):\n",
    "        outs = tf.layers.conv2d(outs, 128, 3, padding = 'same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2)\n",
    "    outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "    #fully connected layer \n",
    "    outs = tf.layers.dense(outs, 256)\n",
    "    outs = tf.nn.relu(outs)\n",
    "    outs = tf.layers.dense(outs, 10)\n",
    "    #cross entropy\n",
    "    one_hot = tf.one_hot(by,10)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels = one_hot, logits = outs)\n",
    "\n",
    "    #optimizer\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    opt = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "    \n",
    "    preds = tf.cast(tf.argmax(tf.nn.softmax(outs), axis = 1),tf.int32)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(by, preds), tf.float32)) #label, prediction\n",
    "    \n",
    "    return {\n",
    "        'loss' : loss, 'opt' : opt, 'preds' : preds, 'acc' : acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = (None, 28,28))\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n",
    "ours = model(X,by)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "num_samples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-6-f8e414da0f75>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/first/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_361_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'first/conv2d/Conv2D', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-9c7e4bb2288a>\", line 4, in <module>\n    ours = model(X,by)\n  File \"<ipython-input-6-f8e414da0f75>\", line 4, in model\n    outs = tf.layers.conv2d(X, 128, 3, padding = 'same') #filter : 128, kernel : 3\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-6-f8e414da0f75>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/first/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_361_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node first/conv2d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/first/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_361_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16a5a17f4503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#             if ind_% num_display == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#                 print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test3 loss :{0:.4f}, acc : {1:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-6-f8e414da0f75>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/first/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_361_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'first/conv2d/Conv2D', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-9c7e4bb2288a>\", line 4, in <module>\n    ours = model(X,by)\n  File \"<ipython-input-6-f8e414da0f75>\", line 4, in model\n    outs = tf.layers.conv2d(X, 128, 3, padding = 'same') #filter : 128, kernel : 3\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-6-f8e414da0f75>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/first/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_361_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for ind_epoch in range(0,num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch +1))\n",
    "        for ind_ in range(0, int(num_samples/batch_size)) : \n",
    "            batch_X = train_data[ind_ * batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = train_label[ind_ * batch_size:(ind_+1)*batch_size]\n",
    "            \n",
    "            _, cur_loss, cur_acc = sess.run([ours['opt'], ours['loss'], ours['acc']], feed_dict = {X:batch_X, by:batch_by})\n",
    "#             if ind_% num_display == 0:\n",
    "#                 print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "            _, cur_loss, cur_acc = sess.run([ours['opt'], ours['loss'], ours['acc']], feed_dict={X:test_data, by:test_label})\n",
    "            print('Test3 loss :{0:.4f}, acc : {1:.4f}'.format(cur_loss, cur_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
